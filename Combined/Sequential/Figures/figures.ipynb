{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Reuse Categories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['All', 'All', 'All', 'IP+CP+MC', 'All', 'IP+MC', 'All', 'All', 'All', 'All', 'All'] most pop\n[0.9, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0] reused_count\n[0.1, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0] special_count\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# figure 5\n",
    "# Lesion analysis\n",
    "##################################################\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_lesion_analysis():\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=[5, 5])\n",
    "\n",
    "    #plt.subplot2grid([1, 3], [0, 0])\n",
    " \n",
    "    \"\"\"\n",
    "    dir = \"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data/\"\n",
    "    files = glob.glob(os.path.join(dir, \"perf_*.npy\"))\n",
    "    #print(files)\n",
    "    files.sort()\n",
    "\n",
    "    all_categs = []\n",
    "    all_counts = []\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        fits = np.load(file)\n",
    "        # if np.prod(fits) > 0.8:\n",
    "        fits = fits**(1/4)\n",
    "        if np.min(fits) > 0.0:\n",
    "            ind = file.split(\"/\")[-1].split(\".\")[-2].split(\"_\")[-1]\n",
    "            ipp = np.load(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data/lesions_IP_\" + str(ind) + \".npy\") #10 values, one for each neuron in a circuit\n",
    "            cpp = np.load(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data/lesions_CP_\" + str(ind) + \".npy\")\n",
    "            lwp = np.load(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data/lesions_LW_\" + str(ind) + \".npy\")\n",
    "            mcp = np.load(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data/lesions_MC_\" + str(ind) + \".npy\")\n",
    "\n",
    "            # Stats on neurons for Ablations\n",
    "            \n",
    "            Threshold = 0.85\n",
    "            count = np.zeros(16)\n",
    "            for (ip_neuron, cp_neuron, lw_neuron, mc_neuron) in zip(ipp, cpp, lwp, mcp):\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron > Threshold and lw_neuron > Threshold and mc_neuron > Threshold\n",
    "                ):  # no task neurons\n",
    "                    count[0] += 1\n",
    "                if (\n",
    "                    ip_neuron <= Threshold and cp_neuron > Threshold and lw_neuron > Threshold and mc_neuron > Threshold\n",
    "                ):  # ip task neurons\n",
    "                    count[1] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron <= Threshold and lw_neuron > Threshold and mc_neuron > Threshold\n",
    "                ):  # cp task neurons\n",
    "                    count[2] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron > Threshold and lw_neuron <= Threshold and mc_neuron > Threshold\n",
    "                ):  # lw task neurons\n",
    "                    count[3] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron > Threshold and lw_neuron > Threshold and mc_neuron <= Threshold\n",
    "                ):  # mc task neurons\n",
    "                    count[4] += 1\n",
    "                if (\n",
    "                    ip_neuron <= Threshold and cp_neuron <= Threshold and lw_neuron > Threshold and mc_neuron > Threshold\n",
    "                ):  # ip and cp\n",
    "                    count[5] += 1\n",
    "                if (\n",
    "                    ip_neuron <= Threshold and cp_neuron > Threshold and lw_neuron <= Threshold and mc_neuron > Threshold\n",
    "                ):  # ip and lw\n",
    "                    count[6] += 1\n",
    "                if (\n",
    "                    ip_neuron <= Threshold and cp_neuron > Threshold and lw_neuron > Threshold and mc_neuron <= Threshold\n",
    "                ):  # ip and mc\n",
    "                    count[7] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron <= Threshold and lw_neuron <= Threshold and mc_neuron > Threshold\n",
    "                ):  #cp and lw\n",
    "                    count[8] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron <= Threshold and lw_neuron > Threshold and mc_neuron <= Threshold\n",
    "                ):  #cp and mc\n",
    "                    count[9] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron > Threshold and lw_neuron <= Threshold and mc_neuron <= Threshold\n",
    "                ):  #lw and mc\n",
    "                    count[10] += 1\n",
    "                if ( \n",
    "                    ip_neuron <= Threshold and cp_neuron <= Threshold and lw_neuron <= Threshold and mc_neuron > Threshold\n",
    "                ): #ip, cp, lw\n",
    "                    count[11] += 1\n",
    "                if ( \n",
    "                    ip_neuron <= Threshold and cp_neuron <= Threshold and lw_neuron > Threshold and mc_neuron <= Threshold\n",
    "                ): #ip, cp, mc\n",
    "                    count[12] += 1\n",
    "                if (\n",
    "                    ip_neuron <= Threshold and cp_neuron > Threshold and lw_neuron <= Threshold and mc_neuron <= Threshold\n",
    "                ): #ip, lw, mc\n",
    "                    count[13] += 1\n",
    "                if (\n",
    "                    ip_neuron > Threshold and cp_neuron <= Threshold and lw_neuron <= Threshold and mc_neuron <= Threshold\n",
    "                ): #cp, lw, mc\n",
    "                    count[14] += 1\n",
    "                if (\n",
    "                    ip_neuron <=  Threshold and cp_neuron <= Threshold and lw_neuron <= Threshold and mc_neuron <= Threshold\n",
    "                ):  #all \n",
    "                    count[15] += 1\n",
    "                \n",
    "\n",
    "            # making it dataframe ready\n",
    "            all_counts.append(count) #count is a 1x15 array for each agent. All_counts is 15xensemble size \n",
    "            #all categories: reuse and specialization\n",
    "            categs = [\"None\",\"IP\",\"CP\",\"LW\",\"MC\",\"IP+CP\",\"IP+LW\",\"IP+MC\",\"CP+LW\",\"CP+MC\",\"LW+MC\",\"IP+CP+LW\",\"IP+CP+MC\",\"IP+LW+MC\",\"CP+LW+MC\",\"All\"]\n",
    "            #2-neuron reuse categs:\n",
    "            #5,6,7,8,9,10\n",
    "            #3-neuron reuse categs:\n",
    "            #11,12,13,14\n",
    "            #4-neuron reuse categs: 15\n",
    "            for cg, ct in zip(categs, count): #15 categories, 15 slots in count, all_categs keeps track of categories for each agent\n",
    "                all_categs.append([cg, ct, i])\n",
    "    #print(all_counts)\n",
    "    #Pairwise data\n",
    "    #ip_inv = []\n",
    "    #cp_inv = []\n",
    "    #lw_inv = []\n",
    "    mc_inv = []\n",
    "    #ip_cp = []\n",
    "    #ip_lw = []\n",
    "    ip_mc = []\n",
    "    #ip_mc_lab = []\n",
    "    #cp_lw = []\n",
    "    cp_mc = []\n",
    "    #cp_mc_lab = []\n",
    "    lw_mc = []\n",
    "    ip_cp_mc = []\n",
    "    ip_lw_mc = []\n",
    "    cp_lw_mc = []\n",
    "\n",
    "    all_tasks = []\n",
    "    no_tasks = []\n",
    "    task_labels = []\n",
    "    most_pop = []\n",
    "\n",
    "\n",
    "    for count in all_counts: #each set of categories, in the ensemble (all_counts)\n",
    "        #set of categories for each agent\n",
    "\n",
    "        #ip_cp.append(count[5])\n",
    "        #ip_lw.append(count[6])\n",
    "        mc_inv.append(count[4]) #number of MC-exclusive neurons in each agent\n",
    "        ip_mc.append(count[7])\n",
    "        cp_mc.append(count[9])\n",
    "        lw_mc.append(count[10])\n",
    "        ip_cp_mc.append(count[12])\n",
    "        ip_lw_mc.append(count[13])\n",
    "        cp_lw_mc.append(count[14])\n",
    "        all_tasks.append(count[15])\n",
    "        no_tasks.append(count[0])\n",
    "        count = list(count)\n",
    "        pop = count.index(max(count)) #calculate highest value in count\n",
    "        cat_pop = categs[pop] #get corresponding category \n",
    "        most_pop.append(cat_pop)\n",
    "    #print(most_pop)\n",
    "        \n",
    "    \n",
    "     \n",
    "\n",
    "    \"\"\"\n",
    "        all_tasks.append(count[15])\n",
    "        no_tasks.append(count[0])\n",
    "        if count[4] > 0:\n",
    "            task_labels[0] = 'MC'\n",
    "        if count[7] > 0:\n",
    "            task_labels[1] = 'MC'\n",
    "        if count[9] > 0:\n",
    "            task_labels[2] = 'CPMC'\n",
    "        if count[10] > 0:\n",
    "            task_labels[3] = 'LWMC'\n",
    "        if count[12] > 0:\n",
    "            task_labels[4] = 'IPCPMC'\n",
    "        if count[13] > 0:\n",
    "            task_labels[5] = 'IPLWMC'\n",
    "        if count[14] > 0:\n",
    "            task_labels[6] = 'CPLWMC'\n",
    "        if count[15] > 0:\n",
    "            task_labels[7] = 'All'\n",
    "        if count[0] > 0:\n",
    "            task_labels[8] = 'None'\n",
    "        else:\n",
    "            pass\n",
    "        print(len(task_labels))\n",
    "        ensemble_labels.append(task_labels)\n",
    "    #print(mc_inv)\n",
    "    #print(lw_mc)\n",
    "    #print(ensemble_labels)\n",
    "    \"\"\"\n",
    "    #np.save(\"./Combined/Sequential/Data\"+\"/MC\"+\".npy\",mc_inv)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/ip_mc\"+\".npy\",ip_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/cp_mc\"+\".npy\",cp_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/lw_mc\"+\".npy\",lw_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/ip_cp_mc\"+\".npy\",ip_cp_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/ip_lw_mc\"+\".npy\",ip_lw_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/cp_lw_mc\"+\".npy\",cp_lw_mc)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/all\"+\".npy\",all_tasks)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/none\"+\".npy\",no_tasks)\n",
    "    print(most_pop, 'most pop')\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/most_pop_cat\"+\".npy\",most_pop)\n",
    "    \n",
    "\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/task_labels\"+\".npy\",task_labels)\n",
    "\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/ip_mc_lab\"+\".npy\",ip_mc_lab)\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/cp_mc_lab\"+\".npy\",cp_mc_lab)\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/lw_mc_lab\"+\".npy\",lw_mc_lab)\n",
    "    \n",
    "\n",
    "#2-neuron reuse categs:\n",
    "#5,6,7,8,9,10\n",
    "#3-neuron reuse categs:\n",
    "#11,12,13,14\n",
    "#4-neuron reuse categs: 15\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # plot specialization and reuse\n",
    "    plt.figure(figsize=[4, 4])\n",
    "    #ax2 = plt.subplot2grid([1, 3], [0, 2], adjustable=\"box\", aspect=1)\n",
    "    #ax2.plot([-0.5, 21.5], [21.5, -0.5], \"k\", linewidth=0.7)\n",
    "    #ax2 = plt.subplot2grid([1, 4], [0, 4], adjustable=\"box\", aspect=1)\n",
    "    plt.plot([0.0, 1.0], [0.0, 1.0], \"k\", linewidth=0.7)\n",
    "    \"\"\"\n",
    "    #count_data = []\n",
    "    reused_count = []\n",
    "    reused_count_2 = []\n",
    "    reused_count_3 = []\n",
    "    reused_count_4 = []\n",
    "    special_count = []\n",
    "    #count_data_prop = []\n",
    "    for count in all_counts:\n",
    "        # plt.scatter(count[1]+count[2]+count[3], np.sum(count[4:]), c=\"C0\")\n",
    "        #count_data.append([count[1] + count[2] + count[3] + count[4], np.sum(count[5:])])\n",
    "        #count_data_prop.append([((count[1] + count[2] + count[3] + count[4])/20), ((np.sum(count[5:]))/20)])\n",
    "        #count_data_prop.append([((np.sum(count[:4]))/20), ((np.sum(count[5:]))/20)])\n",
    "        reused_count.append((np.sum(count[5:]))/10)\n",
    "        reused_count_2.append((count[5]+count[6]+count[7]+count[8]+count[9]+count[10])/10)\n",
    "        reused_count_3.append((count[1]+count[12]+count[13]+count[14])/10)\n",
    "        reused_count_4.append((count[15])/10)\n",
    "        #special_count.append((np.sum(count[1:5]))/20)\n",
    "        special_count.append((count[1]+count[2]+count[3]+count[4])/10)\n",
    "        #print(len(count_data_prop))\n",
    "    \n",
    "    print(reused_count, 'reused_count')\n",
    "    print(special_count, 'special_count')\n",
    "   # print(reused_count_2)\n",
    "  #  print(reused_count_3)\n",
    "  #  print(reused_count_4)\n",
    "  #  print(special_count)\n",
    "\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/reused_prop\"+\".npy\",reused_count)\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/reused_prop_2\"+\".npy\",reused_count_2)\n",
    "    #np.save(\"./Combined/4T_2x5/Data\"+\"/reused_prop_3\"+\".npy\",reused_count_3)\n",
    "   # np.save(\"./Combined/4T_2x5/Data\"+\"/reused_prop_4\"+\".npy\",reused_count_4)\n",
    "    np.save(\"C:/Users/benso/Desktop/Projects/Neural Reuse/Neural_Reuse_New/Combined/Sequential/Data\"+\"/special_prop\"+\".npy\",special_count)\n",
    "\n",
    "\n",
    "\n",
    "plot_lesion_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}